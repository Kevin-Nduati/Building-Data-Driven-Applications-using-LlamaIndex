{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With LLamaIndex, you can rapidly create smart LLMs that can adapt to your specific use case. Instead of relying only on their generic pre-trained knowledge, yopu can inject targeted information that will give you accurate, relevant answers. It provides an easy way to connect external datasets to LLMs such as GPT-4, claude and LLama. LLamaIndex guides the LLM to pull from trusted sources you provide, and these sources could contain both structured and unstructured data. \n",
    "\n",
    "LlamaIndec woll do the following:\n",
    "* Build a search engine for your document collection\n",
    "* Create a company chatbot with customized knowledge\n",
    "* Generic  summaries of large reports or papers\n",
    "* Develop a smart assistant for complex workflows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('files').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"summarize each document in a few sentences\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
